# Vet RAG Project: ìˆ˜ì˜í•™ ì „ë¬¸ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ

ì´ í”„ë¡œì íŠ¸ëŠ” ìˆ˜ì˜í•™ ë„ë©”ì¸ì— íŠ¹í™”ëœ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ê³ í’ˆì§ˆì˜ ë°ì´í„° íë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •(Fine-tuning)í•˜ì—¬ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥ (ì¶”ë¡  íŒŒì´í”„ë¼ì¸)

ì´ ì €ì¥ì†ŒëŠ” **ì¶”ë¡ (Inference) ì „ìš©**ì…ë‹ˆë‹¤. íŒ€ì›ë“¤ì€ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ì‹¤í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (4ë‹¨ê³„)
0. **Rationale Generation (RAG^2)**: Generator ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëª¨í˜¸í•œ ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ì í•©í•œ ì˜í•™ì  ê·¼ê±°ë¡œ ë³€í™˜.
1. **Retrieval (Top-50)**: Bi-Encoderë¡œ ë¹ ë¥´ê²Œ í›„ë³´ ë¬¸ì„œ ê²€ìƒ‰.
2. **Reranking (Top-3)**: í•™ìŠµëœ Cross-Encoderë¡œ ì •ë°€ ì¬ìˆœìœ„í™”.
3. **Generation**: Qwen 2.5 (4-bit Quantized) LLMìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±.

### í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
íŒ€ì›ë“¤ì´ ì‹¤í—˜í•  ìˆ˜ ìˆëŠ” ì£¼ìš” íŒŒì¼:
- **`src/module_augment.py`**: `build_prompt()` í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ í”„ë¡¬í”„íŠ¸ í˜•ì‹ ë³€ê²½
- **`config.yaml`**: ëª¨ë¸ ì„¤ì •, íŒŒë¼ë¯¸í„° ì¡°ì •

## ğŸ’» ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬í•­

- **GPU**: VRAM 8GB ì´ìƒ (RTX 3060/4060 ì´ìƒ ê¶Œì¥)
- **RAM**: 16GB ì´ìƒ
- **OS**: Windows/Linux (Windowsì˜ ê²½ìš° WSL2 ê¶Œì¥)
- **Python**: 3.8 ì´ìƒ

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
catholic_retriver/
â”œâ”€â”€ data/                       # ì›ë³¸ ë°ì´í„° (ë¬¸ì„œ, ì§ˆì˜ì‘ë‹µ)
â”‚   â”œâ”€â”€ TS_ë§ë­‰ì¹˜ë°ì´í„°_ë‚´ê³¼/    # ë¬¸ì„œ ë°ì´í„° (JSON í˜•ì‹)
â”‚   â””â”€â”€ Training/               # ì§ˆì˜ì‘ë‹µ ë°ì´í„° (ZIP í˜•ì‹)
â”œâ”€â”€ exper/                      # ì‹¤í—˜ ë° í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”œâ”€â”€ vet_rag_project/            # ë©”ì¸ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ config.yaml             # ì„¤ì • íŒŒì¼ (ëª¨ë¸, íŒŒë¼ë¯¸í„° ë“±)
â”‚   â”œâ”€â”€ main_curation.py        # ì¶”ë¡  ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ requirements.txt        # ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ëª©ë¡
â”‚   â”œâ”€â”€ upload_model.py         # ëª¨ë¸ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (ì°¸ê³ ìš©)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ data_loader.py      # ë°ì´í„° ë¡œë”© ë° ì²­í‚¹
â”‚       â”œâ”€â”€ embedding.py        # KmBERT ì„ë² ë”© ëª¨ë“ˆ
â”‚       â”œâ”€â”€ module_augment.py   # í”„ë¡¬í”„íŠ¸ ìƒì„± ëª¨ë“ˆ â­ (íŒ€ì›ë“¤ì´ ìˆ˜ì •í•  ë¶€ë¶„)
â”‚       â””â”€â”€ rag_pipeline.py     # ì „ì²´ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (Rationale->Retrieval->Rerank->Gen)
â””â”€â”€ README.md                   # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
```

## ğŸ“Š ë°ì´í„° ì¤€ë¹„

### ë¬¸ì„œ ë°ì´í„°
`data/TS_ë§ë­‰ì¹˜ë°ì´í„°_ë‚´ê³¼/` í´ë”ì— ë‹¤ìŒ í˜•ì‹ì˜ JSON íŒŒì¼ì„ ì¤€ë¹„í•˜ì„¸ìš”:
```json
{
  "title": "ë¬¸ì„œ ì œëª©",
  "department": "ë‚´ê³¼",
  "disease": "ë³¸ë¬¸ ë‚´ìš©..."
}
```

### ì§ˆì˜ì‘ë‹µ ë°ì´í„°
`data/Training/02.ë¼ë²¨ë§ë°ì´í„°/TL_ì§ˆì˜ì‘ë‹µë°ì´í„°_ë‚´ê³¼.zip` í˜•ì‹ìœ¼ë¡œ ì¤€ë¹„í•˜ì„¸ìš”.
ZIP íŒŒì¼ ë‚´ë¶€ì—ëŠ” ë‹¤ìŒ í˜•ì‹ì˜ JSON íŒŒì¼ë“¤ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:
```json
{
  "question": "ì§ˆë¬¸ ë‚´ìš©",
  "answer": "ë‹µë³€ ë‚´ìš©"
}
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰

### 0. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (í•„ìˆ˜)

#### OpenAI API í‚¤ ì„¤ì • (Answer Generationìš©)

1. **`.env` íŒŒì¼ ìƒì„±**:
   ```bash
   cd vet_rag_project
   # .env.exampleì´ ìˆë‹¤ë©´ ë³µì‚¬, ì—†ë‹¤ë©´ ìƒˆë¡œ ìƒì„±
   ```

2. **`.env` íŒŒì¼ í¸ì§‘**:
   ```bash
   # .env íŒŒì¼ ë‚´ìš©
   OPENAI_API_KEY=sk-your-openai-api-key-here
   WANDB_DISABLED=true
   ```
   
   > **ì°¸ê³ **: OpenAI API í‚¤ëŠ” https://platform.openai.com/api-keys ì—ì„œ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Hugging Face í† í° ì„¤ì • (ëª¨ë¸ ì—…ë¡œë“œìš©, ì„ íƒì‚¬í•­)

ëª¨ë¸ì„ Hugging Faceì— ì—…ë¡œë“œí•˜ë ¤ë©´ í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤. (íŒ€ì›ë“¤ì€ í† í° ì—†ì´ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥)

1. **Hugging Face í† í° ë°œê¸‰**:
   - https://huggingface.co/settings/tokens ì ‘ì†
   - "New token" í´ë¦­ â†’ **"Write"** ê¶Œí•œìœ¼ë¡œ ìƒì„± (ì—…ë¡œë“œìš©)
   - í† í° ë³µì‚¬

2. **`.env` íŒŒì¼ì— ì¶”ê°€** (ì„ íƒì‚¬í•­):
   ```bash
   HF_TOKEN=hf_your_actual_token_here
   ```
   
   > **ì°¸ê³ **: ëª¨ë¸ ë‹¤ìš´ë¡œë“œë§Œ í•˜ëŠ” ê²½ìš° í† í°ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. (Public ë¦¬í¬ì§€í† ë¦¬)

### 1. í™˜ê²½ ì„¤ì •
```bash
cd vet_rag_project
pip install -r requirements.txt

# 4-bit ì–‘ìí™”ë¥¼ ìœ„í•œ ì¶”ê°€ ì„¤ì¹˜ (Windows)
pip install bitsandbytes accelerate
```

### 2. ì¶”ë¡  (Inference)

#### ëª…ë ¹ì¤„ ëª¨ë“œ
```bash
python main_curation.py --mode inference --query "ê°•ì•„ì§€ê°€ êµ¬í† ë¥¼ í•´ìš”. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"
```

#### ëŒ€í™”í˜• ëª¨ë“œ
```bash
python main_curation.py --mode inference
```
- ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
- `quit` ë˜ëŠ” `exit`ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.

**ì°¸ê³ :**
- ì²« ì‹¤í–‰ ì‹œ Hugging Faceì—ì„œ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤ (í† í° ë¶ˆí•„ìš”).
- RTX 4060 ë“± ì¼ë°˜ GPUì—ì„œë„ êµ¬ë™ ê°€ëŠ¥í•˜ë„ë¡ Qwen ëª¨ë¸ì„ 4-bitë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
- í”„ë¡¬í”„íŠ¸ ìˆ˜ì •: `src/module_augment.py`ì˜ `build_prompt()` í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.

## ğŸ“¤ ëª¨ë¸ ê³µìœ  (Hugging Face)

### ëª¨ë¸ ì—…ë¡œë“œ (ì‘ì„±ìë§Œ ìˆ˜í–‰)

í•™ìŠµëœ ëª¨ë¸ì„ Hugging Faceì— ê³µê°œ ë¦¬í¬ì§€í† ë¦¬ë¡œ ì—…ë¡œë“œí•˜ì—¬ íŒ€ì›ë“¤ê³¼ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. **`upload_model.py` íŒŒì¼ ìˆ˜ì •**:
   ```python
   # upload_model.py íŒŒì¼ì„ ì—´ì–´ì„œ ì•„ë˜ ì„¤ì •ì„ ìˆ˜ì •í•˜ì„¸ìš”
   MY_TOKEN = "hf_your_actual_token_here"  # Hugging Face Write í† í°
   REPO_ID = "your-username/your-model-name"  # ì˜ˆ: "gildong/vet-rag-reranker"
   MODEL_DIR = "./results/bert_top25percent/final_model"  # ì—…ë¡œë“œí•  ëª¨ë¸ ê²½ë¡œ
   ```

2. **ëª¨ë¸ ì—…ë¡œë“œ ì‹¤í–‰**:
   ```bash
   python upload_model.py
   ```
   
   - ëª¨ë¸ì´ Hugging Faceì— ê³µê°œ ë¦¬í¬ì§€í† ë¦¬ë¡œ ì—…ë¡œë“œë©ë‹ˆë‹¤.
   - íŒ€ì›ë“¤ì€ **í† í° ì—†ì´** ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

3. **`config.yaml` ì„¤ì •** (ì—…ë¡œë“œ í›„):
   ```yaml
   training:
     huggingface_repo_id: "your-username/your-model-name"  # ì£¼ì„ í•´ì œí•˜ê³  ë¦¬í¬ì§€í† ë¦¬ ì´ë¦„ ì…ë ¥
   ```

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì‚¬ìš© (íŒ€ì›ìš©)

íŒ€ì›ë“¤ì€ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ Hugging Faceì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

1. **ì½”ë“œ í´ë¡  ë° ì„¤ì¹˜**:
   ```bash
   git clone <repository-url>
   cd vet_rag_project
   pip install -r requirements.txt
   ```

2. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì •** (`.env` íŒŒì¼):
   ```bash
   OPENAI_API_KEY=sk-your-openai-api-key-here
   ```

3. **`config.yaml` ì„¤ì •**:
   ```yaml
   training:
     huggingface_repo_id: "your-username/your-model-name"  # ì—…ë¡œë“œëœ ëª¨ë¸ ë¦¬í¬ì§€í† ë¦¬ ì´ë¦„
   ```

4. **ì½”ë“œ ì‹¤í–‰**:
   ```bash
   python main_curation.py --mode inference --query "ê°•ì•„ì§€ê°€ êµ¬í† ë¥¼ í•´ìš”"
   ```
   
   - ì²« ì‹¤í–‰ ì‹œ Hugging Faceì—ì„œ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
   - ì´í›„ ì‹¤í–‰ ì‹œì—ëŠ” ìºì‹œëœ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
   - **í† í° ì—†ì´** ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤ (Public ë¦¬í¬ì§€í† ë¦¬).

> **ğŸ’¡ ì¥ì **:
> - íŒ€ì›ë“¤ì€ Hugging Face íšŒì›ê°€ì… ë¶ˆí•„ìš”
> - ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œ ìë™ìœ¼ë¡œ ìƒˆ ë²„ì „ ë‹¤ìš´ë¡œë“œ
> - ë¡œì»¬ ìºì‹±ìœ¼ë¡œ ë¹ ë¥¸ ì¬ì‹¤í–‰

## âš™ï¸ ì„¤ì • (config.yaml)

ì£¼ìš” ì„¤ì • í•­ëª©:

```yaml
# ê²€ìƒ‰ ëª¨ë¸ ì„¤ì •
retrieval:
  model_name: "madatnlp/km-bert"
  top_k: 50

# íë ˆì´ì…˜ìš© LLM (ê°€ë²¼ìš´ ëª¨ë¸ ê¶Œì¥)
llm_scorer:
  model_name: "gpt2"
  alpha_high_std: 0.7
  beta_low_std: 0.7

# ì¶”ë¡ ìš© LLM (ê³ ì„±ëŠ¥ ëª¨ë¸)
# Rationale Generationê³¼ Answer Generationì— ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
llm:
  model_name: "Qwen/Qwen2.5-7B-Instruct"
  quantization: "bnb_4bit"
  gpu_memory_utilization: 0.90
  max_model_len: 4096
  dtype: "float16"

# Rationale Generation ì„¤ì • (RAG^2-style Query Enhancement)
rationale_gen:
  enabled: true  # falseë¡œ ì„¤ì •í•˜ë©´ Rationale Generationì„ ê±´ë„ˆëœë‹ˆë‹¤
  temperature: 0.3  # ë‚®ê²Œ ì„¤ì •í•˜ì—¬ ì¼ê´€ì„± ìˆëŠ” ì¶œë ¥
  top_p: 0.9
  max_tokens: 256  # Rationaleì€ ê°„ê²°í•˜ê²Œ

# í•™ìŠµ ì„¤ì •
training:
  output_dir: "./results/bert_top25percent"
  num_train_epochs: 3
  per_device_train_batch_size: 16
  learning_rate: 2e-5
  save_total_limit: 1
  # Hugging Face ëª¨ë¸ ì €ì¥ì†Œ (ì„ íƒì‚¬í•­)
  # huggingface_repo_id: "your-username/your-model-name"  # ëª¨ë¸ ì—…ë¡œë“œ í›„ ì£¼ì„ í•´ì œ
```

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥ ë° ìµœì í™”

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
- **ìˆœì°¨ì  ëª¨ë¸ ë¡œë”©**: íë ˆì´ì…˜ ì‹œ KmBERT â†’ LLM Scorer â†’ Cross-Encoder ìˆœìœ¼ë¡œ ë¡œë“œ/ì–¸ë¡œë“œ
- **ì¤‘ê°„ ê²°ê³¼ ìºì‹±**: ì„ë² ë”©, PPL ì ìˆ˜ë¥¼ `cache/` í´ë”ì— ì €ì¥í•˜ì—¬ ì¬ì‚¬ìš©
- **4-bit ì–‘ìí™”**: `bitsandbytes`ë¥¼ ì‚¬ìš©í•˜ì—¬ Qwen 7B ëª¨ë¸ì„ VRAM 8GB í™˜ê²½ì—ì„œ êµ¬ë™
- **ëª¨ë¸ ì¬ì‚¬ìš©**: Generator ëª¨ë¸(LLM)ì„ Rationale Generationê³¼ Answer Generationì— ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ

### ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬
- **5ë‹¨ê³„ íë ˆì´ì…˜**: Retrieval â†’ LLM Scoring â†’ Graph Refinement â†’ Labeling â†’ Validation
- **ìë™ ë¼ë²¨ë§**: ìƒìœ„ 5ê°œ ë¬¸ì„œëŠ” `label=1`, ë‚˜ë¨¸ì§€ëŠ” `label=0`ìœ¼ë¡œ ìë™ í• ë‹¹
- **ì ìˆ˜ ê¸°ë°˜ í•„í„°ë§**: PPL ì ìˆ˜ì™€ ê·¸ë˜í”„ ì „íŒŒ ì ìˆ˜ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ì í•©ì„± í‰ê°€

## ğŸ“ˆ ì„±ëŠ¥ ë° ê²°ê³¼

- **ê²€ìƒ‰ ì •í™•ë„**: Cross-Encoder ì¬ìˆœìœ„í™”ë¥¼ í†µí•´ Top-3 ì •í™•ë„ ëŒ€í­ í–¥ìƒ
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: RTX 4060 (8GB VRAM)ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ êµ¬ë™
- **ì¶”ë¡  ì†ë„**: Bi-Encoder (ë¹ ë¥¸ ê²€ìƒ‰) + Cross-Encoder (ì •ë°€ ì¬ìˆœìœ„í™”) ì¡°í•©ìœ¼ë¡œ ìµœì í™”
- **RAG^2 í†µí•©**: Rationale Generationì„ í†µí•´ ëª¨í˜¸í•œ ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ì í•©í•œ ì¿¼ë¦¬ë¡œ ìë™ ë³€í™˜

## ğŸ› ë¬¸ì œ í•´ê²° (Troubleshooting)

### CUDA Out of Memory ì—ëŸ¬
```bash
# config.yamlì—ì„œ batch_size ì¤„ì´ê¸°
per_device_train_batch_size: 8  # 16 â†’ 8ë¡œ ë³€ê²½
```

### vLLM ì„¤ì¹˜ ì‹¤íŒ¨ (Windows)
- Windowsì—ì„œëŠ” `vllm` ì„¤ì¹˜ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìë™ìœ¼ë¡œ `transformers` + `bitsandbytes`ë¡œ fallbackë©ë‹ˆë‹¤.

### ìºì‹œ ì´ˆê¸°í™”
```bash
# cache í´ë” ì‚­ì œ í›„ ì¬ì‹¤í–‰
Remove-Item -Recurse -Force cache
python main_curation.py --mode curate
```

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬ ë° êµìœ¡ ëª©ì ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ™ ê°ì‚¬ì˜ ë§

- **KmBERT**: í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì œê³µ
- **Qwen Team**: ê³ ì„±ëŠ¥ í•œêµ­ì–´ LLM ì œê³µ
- **Hugging Face**: ëª¨ë¸ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœê³„ ì§€ì›
#   c a t h o l i c _ r e t r e i v a l  
 