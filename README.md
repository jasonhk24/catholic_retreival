# ğŸ¥ Vet RAG Project: ìˆ˜ì˜í•™ ì „ë¬¸ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GPU Required](https://img.shields.io/badge/GPU-Required-green.svg)](https://www.nvidia.com/ko-kr/)

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

**ìˆ˜ì˜í•™ ë„ë©”ì¸ íŠ¹í™” RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œ**ìœ¼ë¡œ, ë°˜ë ¤ë™ë¬¼ ë³´í˜¸ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì˜í•™ì ìœ¼ë¡œ ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•
- âœ… **ê³ í’ˆì§ˆ ë°ì´í„° íë ˆì´ì…˜**: LLM + ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ìë™ í•™ìŠµ ë°ì´í„° ìƒì„±
- âœ… **RAGÂ² í†µí•©**: OpenAI APIë¥¼ í™œìš©í•œ ì¿¼ë¦¬ í™•ì¥ìœ¼ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ
- âœ… **4ë‹¨ê³„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸**: Rationale â†’ Retrieval â†’ Reranking â†’ Generation
- âœ… **GPU ë©”ëª¨ë¦¬ ìµœì í™”**: RTX 4060 (8GB VRAM)ì—ì„œ ì•ˆì •ì  êµ¬ë™
- âœ… **êµ¬ì¡°í™”ëœ ë‹µë³€**: ì§„ë‹¨/í‰ê°€, ì¡°ì¹˜ì‚¬í•­, ì£¼ì˜ì‚¬í•­, ê·¼ê±° ìš”ì•½ í˜•ì‹

---

## ğŸš€ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1ï¸âƒ£ ë°ì´í„° íë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸
```
ì›ë³¸ ë°ì´í„° (ë¬¸ì„œ + ì§ˆë¬¸)
    â†“
ã€Phase 1ã€‘ Retrieval (KmBERT Bi-Encoder)
    â†’ Top-50 í›„ë³´ ë¬¸ì„œ ê²€ìƒ‰
    â†“
ã€Phase 2ã€‘ LLM Scoring (GPT-2/Qwen)
    â†’ Perplexity ê¸°ë°˜ ì í•©ì„± í‰ê°€
    â†“
ã€Phase 3ã€‘ Graph Refinement (LightGCN)
    â†’ k-NN ê·¸ë˜í”„ + ì ìˆ˜ ì „íŒŒë¡œ í’ˆì§ˆ ë³´ì •
    â†“
ã€Phase 4ã€‘ Auto-Labeling
    â†’ Top-5 ë¬¸ì„œ: label=1, ë‚˜ë¨¸ì§€: label=0
    â†“
curated_dataset.json (í•™ìŠµ ë°ì´í„°)
```

### 2ï¸âƒ£ ëª¨ë¸ í•™ìŠµ (Cross-Encoder Training)
```
curated_dataset.json
    â†“
Base Model: madatnlp/km-bert
    â†“
Binary Classification Training
    â†’ ì§ˆë¬¸-ë¬¸ì„œ ì—°ê´€ì„± íŒë‹¨
    â†“
results/final_model/ (í•™ìŠµëœ Reranker)
```

### 3ï¸âƒ£ ì¶”ë¡  íŒŒì´í”„ë¼ì¸
```
ì‚¬ìš©ì ì§ˆë¬¸
    â†“
ã€Step 0ã€‘ Rationale Generation (OpenAI gpt-4o-mini)
    â†’ "ê°•ì•„ì§€ê°€ ë…¸ë€ í† ë¥¼ í•´ìš”"
    â†’ "êµ¬í† , ê³µë³µí† , ë‹´ì¦™ ì—­ë¥˜, ìœ„ì¥ê´€ ì§ˆí™˜"
    â†“
ã€Step 1ã€‘ Retrieval (KmBERT Bi-Encoder)
    â†’ Top-50 ë¬¸ì„œ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    â†“
ã€Step 2ã€‘ Reranking (Fine-tuned Cross-Encoder)
    â†’ Top-3 ë¬¸ì„œë¡œ ì •ë°€ ì¬ìˆœìœ„í™”
    â†“
ã€Step 3ã€‘ Answer Generation (OpenAI gpt-4o-mini)
    â†’ êµ¬ì¡°í™”ëœ ë‹µë³€ ìƒì„±
    â†“
ìµœì¢… ë‹µë³€ (4ê°€ì§€ í•­ëª©)
    1. í•µì‹¬ ì§„ë‹¨/í‰ê°€
    2. ì¶”ê°€ ì¡°ì¹˜
    3. ì£¼ì˜ì‚¬í•­
    4. ê·¼ê±° ìš”ì•½
```

---

## ğŸ’» ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬í•­

| í•­ëª© | ìµœì†Œ ì‚¬ì–‘ | ê¶Œì¥ ì‚¬ì–‘ |
|------|----------|----------|
| **GPU** | NVIDIA RTX 3060 (8GB VRAM) | RTX 4060 ì´ìƒ (8GB+ VRAM) |
| **RAM** | 16GB | 32GB |
| **Storage** | 20GB ì—¬ìœ  ê³µê°„ | 50GB+ SSD |
| **OS** | Windows 10/11 | Windows 11 / Linux |
| **Python** | 3.8+ | 3.10+ |

### ì¶”ê°€ ìš”êµ¬ì‚¬í•­
- **OpenAI API Key**: Rationale Generation ë° Answer Generationì— í•„ìš”
- **Hugging Face Token**: ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— í•„ìš” (ë¬´ë£Œ)

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
catholic_retriver/
â”œâ”€â”€ ğŸ“ data/                              # ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ TS_ë§ë­‰ì¹˜ë°ì´í„°_ë‚´ê³¼/              # ìˆ˜ì˜í•™ ë¬¸ì„œ (JSON)
â”‚   â”œâ”€â”€ TS_ë§ë­‰ì¹˜ë°ì´í„°_ì•ˆê³¼/
â”‚   â”œâ”€â”€ TS_ë§ë­‰ì¹˜ë°ì´í„°_ì™¸ê³¼/
â”‚   â”œâ”€â”€ TS_ë§ë­‰ì¹˜ë°ì´í„°_ì¹˜ê³¼/
â”‚   â”œâ”€â”€ TS_ë§ë­‰ì¹˜ë°ì´í„°_í”¼ë¶€ê³¼/
â”‚   â””â”€â”€ Training/02.ë¼ë²¨ë§ë°ì´í„°/         # ì§ˆì˜ì‘ë‹µ ë°ì´í„° (ZIP)
â”‚
â”œâ”€â”€ ğŸ“ vet_rag_project/                   # ë©”ì¸ í”„ë¡œì íŠ¸
â”‚   â”œâ”€â”€ ğŸ“„ config.yaml                   # ì‹œìŠ¤í…œ ì„¤ì • íŒŒì¼ âš™ï¸
â”‚   â”œâ”€â”€ ğŸ“„ main_curation.py              # ì‹¤í–‰ ì§„ì…ì  ğŸš€
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt              # Python íŒ¨í‚¤ì§€ ëª©ë¡
â”‚   â”œâ”€â”€ ğŸ“„ .env                          # API í‚¤ ì„¤ì • (ìƒì„± í•„ìš”)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ src/                          # í•µì‹¬ ëª¨ë“ˆ
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ curator.py               # ë°ì´í„° íë ˆì´ì…˜ (5-Phase)
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ data_loader.py           # ë°ì´í„° ë¡œë”© ë° ì²­í‚¹
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ embedding.py             # KmBERT ì„ë² ë”©
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ graph_refiner.py         # LightGCN ê·¸ë˜í”„ ì „íŒŒ
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ llm_scorer.py            # PPL ê¸°ë°˜ í‰ê°€
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ module_augment.py        # í”„ë¡¬í”„íŠ¸ ìƒì„±
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ rag_pipeline.py          # ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (í•µì‹¬!)
â”‚   â”‚   â””â”€â”€ ğŸ“„ trainer.py               # Cross-Encoder í•™ìŠµ
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ cache/                        # ìºì‹œ ë°ì´í„° (ìë™ ìƒì„±)
â”‚   â”‚   â””â”€â”€ doc_embeddings.npy          # ë¬¸ì„œ ì„ë² ë”© ìºì‹œ
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ results/                      # í•™ìŠµ ê²°ê³¼ (ìë™ ìƒì„±)
â”‚   â”‚   â””â”€â”€ final_model/                # Fine-tuned Reranker
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ logs/                         # í•™ìŠµ ë¡œê·¸ (ìë™ ìƒì„±)
â”‚   â””â”€â”€ ğŸ“„ curated_dataset.json         # íë ˆì´ì…˜ ê²°ê³¼ (ìë™ ìƒì„±)
â”‚
â””â”€â”€ ğŸ“„ README.md                         # ì´ ë¬¸ì„œ
```

### í•µì‹¬ ëª¨ë“ˆ ì„¤ëª…

| íŒŒì¼ëª… | ì—­í•  | ì£¼ìš” ê¸°ëŠ¥ |
|--------|------|----------|
| **config.yaml** | ì„¤ì • ê´€ë¦¬ | ëª¨ë¸ ê²½ë¡œ, í•˜ì´í¼íŒŒë¼ë¯¸í„°, API ì„¤ì • |
| **main_curation.py** | ì‹¤í–‰ ì§„ì…ì  | `--mode curate/train/inference/all` |
| **rag_pipeline.py** | ì¶”ë¡  ì—”ì§„ | Rationale â†’ Retrieval â†’ Rerank â†’ Generation |
| **curator.py** | íë ˆì´ì…˜ | Retrieval â†’ Scoring â†’ Graph â†’ Labeling |
| **module_augment.py** | í”„ë¡¬í”„íŠ¸ | êµ¬ì¡°í™”ëœ ë‹µë³€ í˜•ì‹ ìƒì„± |

---

## ğŸ“Š ë°ì´í„° í˜•ì‹

### 1. ë¬¸ì„œ ë°ì´í„° (Knowledge Base)

**ìœ„ì¹˜**: `data/TS_ë§ë­‰ì¹˜ë°ì´í„°_ë‚´ê³¼/` ë“±

**í˜•ì‹**: JSON íŒŒì¼ (ê° ë¬¸ì„œë‹¹ 1ê°œ íŒŒì¼)
```json
{
  "title": "ê°œ(2íŒ) - ì‹¬ì¥ ì§ˆí™˜",
  "department": "ë‚´ê³¼",
  "disease": "ì‹¬ì¥ì‚¬ìƒì¶©ì¦ì€ ëª¨ê¸°ì— ì˜í•´ ì „íŒŒë˜ëŠ” ê¸°ìƒì¶© ì§ˆí™˜ìœ¼ë¡œ..."
}
```

**í•„ìˆ˜ í•„ë“œ**:
- `title`: ë¬¸ì„œ ì œëª©
- `department`: ì§„ë£Œê³¼ (ë‚´ê³¼, ì™¸ê³¼, ì•ˆê³¼, ì¹˜ê³¼, í”¼ë¶€ê³¼)
- `disease`: ë³¸ë¬¸ ë‚´ìš©

### 2. ì§ˆì˜ì‘ë‹µ ë°ì´í„° (Training Queries)

**ìœ„ì¹˜**: `data/Training/02.ë¼ë²¨ë§ë°ì´í„°/TL_ì§ˆì˜ì‘ë‹µë°ì´í„°_ë‚´ê³¼.zip`

**í˜•ì‹**: ZIP ë‚´ë¶€ì— JSON íŒŒì¼ë“¤
```json
{
  "question": "ê°•ì•„ì§€ê°€ ê¸°ì¹¨ì„ í•´ìš”. ì‹¬ì¥ì‚¬ìƒì¶©ì¼ê¹Œìš”?",
  "answer": "ê¸°ì¹¨ì€ ì‹¬ì¥ì‚¬ìƒì¶©ì˜ ì£¼ìš” ì¦ìƒ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤..."
}
```

**í•„ìˆ˜ í•„ë“œ**:
- `question`: ì‚¬ìš©ì ì§ˆë¬¸
- `answer`: ì •ë‹µ (íë ˆì´ì…˜ ì‹œ ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ, ì°¸ê³ ìš©)

---

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰ ê°€ì´ë“œ

### Step 0ï¸âƒ£: í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (í•„ìˆ˜)

#### 1. **OpenAI API Key ë°œê¸‰** (Rationale & Answer Generationìš©)
```bash
# https://platform.openai.com/api-keys ì ‘ì†
# API Key ìƒì„± ë° ë³µì‚¬
```

#### 2. **Hugging Face Token ë°œê¸‰** (ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)
```bash
# https://huggingface.co/settings/tokens ì ‘ì†
# "New token" í´ë¦­ â†’ "Read" ê¶Œí•œìœ¼ë¡œ ìƒì„±
```

#### 3. **`.env` íŒŒì¼ ìƒì„±**
```bash
cd vet_rag_project

# .env íŒŒì¼ ìƒì„± ë° í¸ì§‘
notepad .env  # Windows
# ë˜ëŠ”
nano .env     # Linux
```

**`.env` íŒŒì¼ ë‚´ìš©**:
```bash
# OpenAI API Key (gpt-4o-mini ì‚¬ìš©)
TOKEN=sk-proj-your_actual_openai_api_key_here

# Hugging Face Token (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ)
HF_TOKEN=hf_your_actual_huggingface_token_here

# Weights & Biases ë¹„í™œì„±í™” (ì„ íƒ)
WANDB_DISABLED=true
```

---

### Step 1ï¸âƒ£: Python í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv .venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
cd vet_rag_project
pip install -r requirements.txt

# GPU ê°€ì† (CUDA ì§€ì›)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

---

### Step 2ï¸âƒ£: ë°ì´í„° íë ˆì´ì…˜ (í•™ìŠµ ë°ì´í„° ìƒì„±)

```bash
python main_curation.py --mode curate
```

**ì²˜ë¦¬ ê³¼ì •**:
1. `data/` í´ë”ì˜ ë¬¸ì„œ ë¡œë”©
2. KmBERTë¡œ ë¬¸ì„œ ì„ë² ë”© ìƒì„± (ìºì‹œë¨)
3. 600ê°œ ì§ˆë¬¸ì— ëŒ€í•´ Top-50 ê²€ìƒ‰
4. LLM Scoring (PPL í‰ê°€)
5. Graph Refinement (LightGCN)
6. `curated_dataset.json` ìƒì„±

**ì˜ˆìƒ ì‹œê°„**: ì•½ 30-60ë¶„ (GPU ì„±ëŠ¥ì— ë”°ë¼ ë‹¤ë¦„)

---

### Step 3ï¸âƒ£: Cross-Encoder í•™ìŠµ

```bash
python main_curation.py --mode train --curated_data curated_dataset.json
```

**í•™ìŠµ ì„¤ì •** (`config.yaml`ì—ì„œ ì¡°ì • ê°€ëŠ¥):
- Epochs: 3
- Batch Size: 16
- Learning Rate: 2e-5
- ê²°ê³¼ ëª¨ë¸: `results/final_model/`

**ì˜ˆìƒ ì‹œê°„**: ì•½ 10-30ë¶„

---

## ğŸ¤— Hugging Face ëª¨ë¸ ì‚¬ìš©ë²•

ë³¸ í”„ë¡œì íŠ¸ì˜ Fine-tuned Cross-EncoderëŠ” Hugging Faceì— ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### ëª¨ë¸ ì •ë³´
- **ëª¨ë¸ëª…**: [JOhyeongi/vet-kmbert-cross-encoder](https://huggingface.co/JOhyeongi/vet-kmbert-cross-encoder)
- **ë² ì´ìŠ¤ ëª¨ë¸**: madatnlp/km-bert
- **íƒœìŠ¤í¬**: Binary Classification (ì§ˆë¬¸-ë¬¸ì„œ ì—°ê´€ì„± íŒë‹¨)
- **ì–¸ì–´**: í•œêµ­ì–´

### ì‚¬ìš© ì˜ˆì œ

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
model = AutoModelForSequenceClassification.from_pretrained(
    "JOhyeongi/vet-kmbert-cross-encoder"
)
tokenizer = AutoTokenizer.from_pretrained(
    "JOhyeongi/vet-kmbert-cross-encoder"
)

# ì¶”ë¡ 
query = "ê°•ì•„ì§€ê°€ êµ¬í† ë¥¼ í•´ìš”"
document = "êµ¬í† ì˜ ì›ì¸ì€..."
inputs = tokenizer([[query, document]], return_tensors="pt", max_length=512)
score = model(**inputs).logits.softmax(dim=1)[0][1].item()

print(f"ì—°ê´€ì„± ì ìˆ˜: {score:.4f}")
```

---

### Step 4ï¸âƒ£: ì¶”ë¡  í…ŒìŠ¤íŠ¸

```bash
python main_curation.py --mode inference \
    --model_path results/final_model \
    --query "ê°•ì•„ì§€ê°€ ë…¸ë€ í† ë¥¼ í•´ìš”. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
========================================
STEP 0: Rationale Generation (RAGÂ²)
========================================
[INFO] [Rationale] Extracted keywords: ['êµ¬í† ', 'ê³µë³µí† ', 'ë‹´ì¦™ ì—­ë¥˜', 'ìœ„ì¥ê´€ ì§ˆí™˜']
[INFO] [Rationale] Expanded Query: ê°•ì•„ì§€ê°€ ë…¸ë€ í† ë¥¼ í•´ìš” [SEP] êµ¬í† , ê³µë³µí† , ë‹´ì¦™ ì—­ë¥˜...

========================================
STEP 1: Retrieval
========================================
[SUCCESS] Retrieved 50 candidates.

========================================
STEP 2: Reranking
========================================
[SUCCESS] Reranked top 3 documents.
   [1] Score: 0.9812 | ê³µë³µí† ëŠ” ìœ„ì‚°ê³¼ ë‹´ì¦™ì´ ì„ì—¬...
   [2] Score: 0.9543 | ë‹´ì¦™ ì—­ë¥˜ëŠ” ì‹­ì´ì§€ì¥ì˜ ë‚´ìš©ë¬¼ì´...
   [3] Score: 0.8901 | ìœ„ì¥ê´€ ì§ˆí™˜ì˜ ì£¼ìš” ì¦ìƒ...

========================================
STEP 3: Answer Generation
========================================

1. **í•µì‹¬ ì§„ë‹¨/í‰ê°€**: 
   ë…¸ë€ìƒ‰ í† ëŠ” ê³µë³µí†  ë˜ëŠ” ë‹´ì¦™ ì—­ë¥˜ì˜ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤...

2. **ì¶”ê°€ ì¡°ì¹˜**: 
   - ì‹ì‚¬ ê°„ê²©ì„ ì¢í˜€ì£¼ì„¸ìš” (í•˜ë£¨ 2-3íšŒ ì†ŒëŸ‰ ê¸‰ì—¬)
   - ì¦ìƒì´ ì§€ì†ë˜ë©´ ë™ë¬¼ë³‘ì› ë°©ë¬¸ í•„ìš”

3. **ì£¼ì˜ì‚¬í•­**: 
   - êµ¬í†  íšŸìˆ˜, ìƒ‰ìƒ, ì‹œê°„ëŒ€ë¥¼ ê¸°ë¡í•˜ì„¸ìš”
   - í˜ˆì•¡ì´ ì„ì´ê±°ë‚˜ ê²€ì€ìƒ‰ì´ë©´ ì¦‰ì‹œ ë³‘ì›

4. **ê·¼ê±° ìš”ì•½**:
   - ê³µë³µí† ëŠ” ìœ„ì‚°ê³¼ ë‹´ì¦™ì´ ì„ì—¬ ë…¸ë€ìƒ‰ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤
   - ì‹ì‚¬ ê°„ê²©ì„ ì¤„ì´ë©´ ì¦ìƒ ê°œì„  ê°€ëŠ¥
```

---

### Step 5ï¸âƒ£: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (í•œ ë²ˆì—)

```bash
python main_curation.py --mode all
```

íë ˆì´ì…˜ â†’ í•™ìŠµ â†’ ì¶”ë¡ ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

---

## âš™ï¸ ì„¤ì • íŒŒì¼ (config.yaml)

### ì£¼ìš” ì„¤ì • í•­ëª©

```yaml
# ========================================
# 1. Knowledge Base (ë¬¸ì„œ ë°ì´í„° ê²½ë¡œ)
# ========================================
knowledge_base:
  directories:
    - "..\\data\\TS_ë§ë­‰ì¹˜ë°ì´í„°_ë‚´ê³¼"
    - "..\\data\\TS_ë§ë­‰ì¹˜ë°ì´í„°_ì•ˆê³¼"
    - "..\\data\\TS_ë§ë­‰ì¹˜ë°ì´í„°_ì™¸ê³¼"
    - "..\\data\\TS_ë§ë­‰ì¹˜ë°ì´í„°_ì¹˜ê³¼"
    - "..\\data\\TS_ë§ë­‰ì¹˜ë°ì´í„°_í”¼ë¶€ê³¼"

# ========================================
# 2. Retrieval (ê²€ìƒ‰ ëª¨ë¸)
# ========================================
retrieval:
  model_name: "madatnlp/km-bert"  # í•œêµ­ì–´ Bi-Encoder
  top_k: 50                        # 1ì°¨ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜

# ========================================
# 3. LLM Scorer (íë ˆì´ì…˜ìš©, ê°€ë²¼ìš´ ëª¨ë¸)
# ========================================
llm_scorer:
  model_name: "gpt2"               # PPL í‰ê°€ìš© (ë¹ ë¦„)
  alpha_high_std: 0.7              # ê³ í’ˆì§ˆ í•„í„°ë§ threshold
  beta_low_std: 0.7                # ì €í’ˆì§ˆ í•„í„°ë§ threshold

# ========================================
# 4. Answer Generation (ì¶”ë¡ ìš©, OpenAI API)
# ========================================
llm:
  model_name: "gpt-4o-mini"        # OpenAI API ëª¨ë¸
  api_key: null                    # .envì˜ TOKEN ì‚¬ìš©
  temperature: 0.7                 # ì°½ì˜ì„± ì¡°ì ˆ (0.0~1.0)
  max_tokens: 512                  # ìµœëŒ€ ìƒì„± í† í° ìˆ˜

# ========================================
# 5. Rationale Generation (ì¿¼ë¦¬ í™•ì¥, OpenAI API)
# ========================================
rationale_gen:
  enabled: true                    # RAGÂ² í™œì„±í™” (ê¶Œì¥)
  model_name: "gpt-4o-mini"        # OpenAI API ëª¨ë¸
  temperature: 0.1                 # ë‚®ê²Œ (ì¼ê´€ì„± ìˆëŠ” í‚¤ì›Œë“œ)
  top_p: 0.9
  max_tokens: 128                  # í‚¤ì›Œë“œë§Œ í•„ìš”
  prompt_template: |               # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ì„ íƒ)
    [ì—­í• ] ìˆ˜ì˜í•™ ê²€ìƒ‰ì–´ í™•ì¥ ì „ë¬¸ê°€
    [ì…ë ¥ ì§ˆë¬¸] {query}
    [ëª©í‘œ] í•µì‹¬ ì˜í•™ í‚¤ì›Œë“œ 3~8ê°œ ì¶”ì¶œ...

# ========================================
# 6. Graph Refinement (LightGCN)
# ========================================
graph:
  k_neighbors: 5                   # k-NN ê·¸ë˜í”„
  lambda_propagation: 0.3          # ì „íŒŒ ê°•ë„
  propagation_steps: 3             # ì „íŒŒ ë ˆì´ì–´ ìˆ˜

# ========================================
# 7. Training (Cross-Encoder í•™ìŠµ)
# ========================================
training:
  model_type: "bert"               # "bert" ë˜ëŠ” "t5"
  output_dir: "./results"
  num_train_epochs: 3
  per_device_train_batch_size: 16  # GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 8ë¡œ ë³€ê²½
  learning_rate: 2e-5
  save_total_limit: 1              # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ë§Œ ìœ ì§€
  logging_steps: 10
  eval_strategy: "epoch"
  load_best_model_at_end: true
```

### ì„¤ì • ë³€ê²½ ê°€ì´ë“œ

| ë³€ê²½í•˜ê³  ì‹¶ì€ ê²ƒ | ìˆ˜ì •í•  ì„¤ì • | ê°’ |
|-----------------|------------|-----|
| **Rationale ë¹„í™œì„±í™”** | `rationale_gen.enabled` | `false` |
| **OpenAI â†’ ë¡œì»¬ ëª¨ë¸** | `llm.model_name` | `"Qwen/Qwen2.5-7B-Instruct"` |
| **GPU ë©”ëª¨ë¦¬ ë¶€ì¡±** | `training.per_device_train_batch_size` | `8` (ë˜ëŠ” `4`) |
| **ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ ì¦ê°€** | `retrieval.top_k` | `100` |
| **í•™ìŠµ ì—í­ ì¦ê°€** | `training.num_train_epochs` | `5` |

---

## ğŸ”§ í•µì‹¬ ê¸°ìˆ  ë° ìµœì í™”

### 1ï¸âƒ£ RAGÂ² (Rationale-Augmented Generation)
```python
# ì‚¬ìš©ì ì§ˆë¬¸ì„ ì˜í•™ ì „ë¬¸ ìš©ì–´ë¡œ ìë™ í™•ì¥
Original Query: "ê°•ì•„ì§€ê°€ ë…¸ë€ í† ë¥¼ í•´ìš”"
    â†“ [OpenAI gpt-4o-mini]
Expanded Query: "ê°•ì•„ì§€ê°€ ë…¸ë€ í† ë¥¼ í•´ìš” [SEP] êµ¬í† , ê³µë³µí† , ë‹´ì¦™ ì—­ë¥˜, ìœ„ì¥ê´€ ì§ˆí™˜"
    â†“
ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ (+15~25%)
```

**íš¨ê³¼**:
- ì¼ìƒ ì–¸ì–´ â†’ ì˜í•™ ìš©ì–´ ìë™ ë³€í™˜
- ë™ì˜ì–´/ê´€ë ¨ì–´ í™•ì¥ìœ¼ë¡œ ê²€ìƒ‰ ì»¤ë²„ë¦¬ì§€ ì¦ê°€
- Zero-shot (ì¶”ê°€ í•™ìŠµ ë¶ˆí•„ìš”)

### 2ï¸âƒ£ 5-Phase ë°ì´í„° íë ˆì´ì…˜
```
Phase 1: Retrieval (KmBERT)
    â†’ Top-50 í›„ë³´ ë¬¸ì„œ
Phase 2: LLM Scoring (GPT-2 PPL)
    â†’ ì í•©ì„± ì ìˆ˜ (0~1)
Phase 3: Graph Refinement (LightGCN)
    â†’ k-NN ê·¸ë˜í”„ + ì ìˆ˜ ì „íŒŒ
Phase 4: Auto-Labeling
    â†’ Top-5: label=1, ë‚˜ë¨¸ì§€: label=0
Phase 5: Validation
    â†’ í’ˆì§ˆ ê²€ì¦ ë° ì €ì¥
```

**íš¨ê³¼**:
- ìˆ˜ë™ ë¼ë²¨ë§ ë¶ˆí•„ìš” (100% ìë™í™”)
- ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
- ê³ í’ˆì§ˆ í•™ìŠµ ë°ì´í„° ìƒì„±

### 3ï¸âƒ£ GPU ë©”ëª¨ë¦¬ ìµœì í™”
- âœ… **ìˆœì°¨ì  ëª¨ë¸ ë¡œë”©**: íë ˆì´ì…˜ ì‹œ ëª¨ë¸ì„ í•˜ë‚˜ì”© ë¡œë“œ/ì–¸ë¡œë“œ
- âœ… **ì¤‘ê°„ ê²°ê³¼ ìºì‹±**: ì„ë² ë”©, PPL ì ìˆ˜ë¥¼ `cache/`ì— ì €ì¥
- âœ… **OpenAI API í™œìš©**: ë¡œì»¬ LLM ëŒ€ì‹  API ì‚¬ìš©ìœ¼ë¡œ VRAM ì ˆì•½
- âœ… **Gradient Checkpointing**: í•™ìŠµ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ

**ê²°ê³¼**: RTX 4060 (8GB VRAM)ì—ì„œ ì•ˆì •ì  êµ¬ë™

### 4ï¸âƒ£ êµ¬ì¡°í™”ëœ ë‹µë³€ ìƒì„±
```
ì‚¬ìš©ì ì§ˆë¬¸ â†’ 4ê°€ì§€ í•­ëª©ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë‹µë³€

1. í•µì‹¬ ì§„ë‹¨/í‰ê°€
   â†’ ì¦ìƒì˜ ì˜í•™ì  ì˜ë¯¸

2. ì¶”ê°€ ì¡°ì¹˜
   â†’ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ í–‰ë™ ê°€ì´ë“œ

3. ì£¼ì˜ì‚¬í•­
   â†’ ìœ„í—˜ ì‹ í˜¸ ë° ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸

4. ê·¼ê±° ìš”ì•½
   â†’ ë‹µë³€ì˜ ì¶œì²˜ (ì°¸ê³  ìë£Œì—ì„œ ì¶”ì¶œ)
```

**íš¨ê³¼**:
- ë³´í˜¸ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹
- Hallucination ë°©ì§€ (ê·¼ê±° ìš”ì•½ í•„ìˆ˜)
- ì¼ê´€ëœ ë‹µë³€ í’ˆì§ˆ

---

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| ì§€í‘œ | Baseline<br>(KmBERTë§Œ) | +Reranking | +RAGÂ²<br>(ìµœì¢…) |
|------|----------------------|-----------|---------------|
| **Top-3 ì •í™•ë„** | 42% | 68% | 79% |
| **ì‘ë‹µ ì‹œê°„** | 0.8ì´ˆ | 2.1ì´ˆ | 2.5ì´ˆ |
| **GPU ë©”ëª¨ë¦¬** | 2.1GB | 3.4GB | 3.6GB |

**í…ŒìŠ¤íŠ¸ í™˜ê²½**: RTX 4060 (8GB), 180ê°œ í‰ê°€ ì§ˆë¬¸

### ì£¼ìš” ê°œì„  ì‚¬í•­
- ğŸ¯ **ê²€ìƒ‰ ì •í™•ë„**: Cross-Encoderë¡œ Top-3 ì •í™•ë„ +37%p
- ğŸš€ **ì¶”ë¡  ì†ë„**: Bi-Encoder (ë¹ ë¥¸ ê²€ìƒ‰) + Cross-Encoder (ì •ë°€ ì¬ìˆœìœ„í™”)
- ğŸ’¾ **ë©”ëª¨ë¦¬ íš¨ìœ¨**: OpenAI API í™œìš©ìœ¼ë¡œ 8GB VRAMì—ì„œ êµ¬ë™
- ğŸ“ **ì¿¼ë¦¬ í™•ì¥**: RAGÂ²ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ +11%p ì¶”ê°€ í–¥ìƒ

---

## ğŸ› ë¬¸ì œ í•´ê²° (Troubleshooting)

### âŒ CUDA Out of Memory

**ì¦ìƒ**: `RuntimeError: CUDA out of memory`

**í•´ê²° ë°©ë²•**:
```yaml
# config.yaml ìˆ˜ì •
training:
  per_device_train_batch_size: 8  # 16 â†’ 8ë¡œ ê°ì†Œ
  gradient_accumulation_steps: 2  # ì¶”ê°€
```

ë˜ëŠ” GPU ë©”ëª¨ë¦¬ ì •ë¦¬:
```python
import torch
torch.cuda.empty_cache()
```

---

### âŒ OpenAI API Key ì˜¤ë¥˜

**ì¦ìƒ**: `InvalidAPIKey` ë˜ëŠ” `Authentication failed`

**í•´ê²° ë°©ë²•**:
1. `.env` íŒŒì¼ì— `TOKEN=sk-proj-...` í˜•ì‹ìœ¼ë¡œ ì €ì¥ í™•ì¸
2. API Keyê°€ ìœ íš¨í•œì§€ í™•ì¸: https://platform.openai.com/api-keys
3. API ì‚¬ìš©ëŸ‰ ì œí•œ í™•ì¸: https://platform.openai.com/usage

---

### âŒ Hugging Face Token ì˜¤ë¥˜

**ì¦ìƒ**: `401 Unauthorized` ë˜ëŠ” `Access denied`

**í•´ê²° ë°©ë²•**:
```bash
# .env íŒŒì¼ í™•ì¸
HF_TOKEN=hf_your_token_here  # í˜•ì‹ í™•ì¸

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
export HF_TOKEN=hf_your_token_here  # Linux/Mac
$env:HF_TOKEN="hf_your_token_here"  # Windows PowerShell
```

---

### âŒ ìºì‹œ íŒŒì¼ ì†ìƒ

**ì¦ìƒ**: `ValueError: could not load embeddings` ë˜ëŠ” ì˜¤ë˜ëœ ìºì‹œ

**í•´ê²° ë°©ë²•**:
```bash
# Windows
Remove-Item -Recurse -Force cache
python main_curation.py --mode curate

# Linux/Mac
rm -rf cache
python main_curation.py --mode curate
```

---

### âŒ ëŠë¦° ì¶”ë¡  ì†ë„

**ì›ì¸**: Rationale Generationì´ í™œì„±í™”ë˜ì–´ ìˆìŒ

**í•´ê²° ë°©ë²•** (ë¹ ë¥¸ ì¶”ë¡ ì´ í•„ìš”í•œ ê²½ìš°):
```yaml
# config.yaml ìˆ˜ì •
rationale_gen:
  enabled: false  # RAGÂ² ë¹„í™œì„±í™”
```

**íš¨ê³¼**:
- ì‘ë‹µ ì‹œê°„: 2.5ì´ˆ â†’ 1.2ì´ˆ
- ì •í™•ë„ í•˜ë½: 79% â†’ 68% (ì•½ -11%p)

---

### âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

**ì¦ìƒ**: `Connection timeout` ë˜ëŠ” `HTTP 503`

**í•´ê²° ë°©ë²•**:
```bash
# 1. ì¸í„°ë„· ì—°ê²° í™•ì¸
ping huggingface.co

# 2. í”„ë¡ì‹œ ì„¤ì • (í•„ìš”ì‹œ)
export HF_HUB_ENABLE_HF_TRANSFER=1

# 3. ëª¨ë¸ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ
huggingface-cli download madatnlp/km-bert
```

---

### âš ï¸ ê²½ê³ : Weights & Biases

**ì¦ìƒ**: `wandb` ë¡œê·¸ì¸ ìš”ì²­

**í•´ê²° ë°©ë²•**:
```bash
# .env íŒŒì¼ì— ì¶”ê°€
WANDB_DISABLED=true
```

---

### í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ëª…
```
í•µì‹¬ íŒŒì´í”„ë¼ì¸ íë¦„:

1. ë°ì´í„° íë ˆì´ì…˜ (main_curation.py --mode curate)
   â””â”€> curator.py (5-Phase)
       â”œâ”€> data_loader.py (ë¬¸ì„œ/ì§ˆë¬¸ ë¡œë”©)
       â”œâ”€> embedding.py (KmBERT ì„ë² ë”©)
       â”œâ”€> llm_scorer.py (PPL í‰ê°€)
       â””â”€> graph_refiner.py (LightGCN ì „íŒŒ)

2. ëª¨ë¸ í•™ìŠµ (main_curation.py --mode train)
   â””â”€> trainer.py (Cross-Encoder í•™ìŠµ)

3. ì¶”ë¡  (main_curation.py --mode inference)
   â””â”€> rag_pipeline.py
       â”œâ”€> generate_rationale() (OpenAI API)
       â”œâ”€> retrieve() (KmBERT)
       â”œâ”€> rerank() (Fine-tuned Cross-Encoder)
       â””â”€> generate() (OpenAI API)
```

---

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025ë…„ 12ì›” 8ì¼
