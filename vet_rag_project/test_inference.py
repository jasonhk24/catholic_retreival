"""
ì¶”ë¡  íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

Fine-tuned Cross-Encoderë¥¼ ì‚¬ìš©í•œ ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
"""

import os
import yaml
from pathlib import Path
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¤ì • ë¡œë“œ
with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

print("="*60)
print("ğŸ§ª ì¶”ë¡  íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
print("="*60)

# 1. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
print("\n[1/5] í™˜ê²½ ë³€ìˆ˜ í™•ì¸...")
hf_token = os.getenv("HF_TOKEN")
openai_key = os.getenv("TOKEN")
print(f"  âœ“ HF_TOKEN: {'ì„¤ì •ë¨' if hf_token else 'âŒ ì—†ìŒ'}")
print(f"  âœ“ OPENAI API KEY: {'ì„¤ì •ë¨' if openai_key else 'âŒ ì—†ìŒ'}")

# 2. ëª¨ë¸ ê²½ë¡œ í™•ì¸
print("\n[2/5] í•™ìŠµëœ ëª¨ë¸ í™•ì¸...")
model_path = Path("results/bert_top25percent")
final_model_path = Path("results/final_model")

if model_path.exists():
    print(f"  âœ“ ëª¨ë¸ ë°œê²¬: {model_path}")
    # ëª¨ë¸ íŒŒì¼ í™•ì¸
    model_files = list(model_path.glob("*"))
    print(f"  âœ“ íŒŒì¼ ìˆ˜: {len(model_files)}")
    print(f"  âœ“ ì£¼ìš” íŒŒì¼: {[f.name for f in model_files[:5]]}")
elif final_model_path.exists():
    print(f"  âœ“ ëª¨ë¸ ë°œê²¬: {final_model_path}")
    model_path = final_model_path
else:
    print("  âŒ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("  ë¨¼ì € 'python main_curation.py --mode train'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    exit(1)

# 3. ë°ì´í„° í™•ì¸
print("\n[3/5] ë°ì´í„° í™•ì¸...")
data_dirs = config["knowledge_base"]["directories"]
doc_count = 0
for data_dir in data_dirs:
    data_path = Path(data_dir)
    if data_path.exists():
        files = list(data_path.glob("*.json"))
        doc_count += len(files)
        print(f"  âœ“ {data_path.name}: {len(files)}ê°œ ë¬¸ì„œ")
    else:
        print(f"  âš  {data_path.name}: ê²½ë¡œ ì—†ìŒ")

print(f"  âœ“ ì´ ë¬¸ì„œ ìˆ˜: {doc_count}ê°œ")

if doc_count == 0:
    print("  âŒ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    exit(1)

# 4. RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
print("\n[4/5] RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...")
try:
    from src.rag_pipeline import VetRAGPipeline
    
    print("  âœ“ ëª¨ë“ˆ import ì„±ê³µ")
    print("  â³ íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    
    pipeline = VetRAGPipeline(
        config_path="config.yaml",
        doc_dir=data_dirs
    )
    
    print("  âœ“ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"  âœ“ ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(pipeline.documents)}ê°œ")
    
except Exception as e:
    print(f"  âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# 5. ì¶”ë¡  í…ŒìŠ¤íŠ¸
print("\n[5/5] ì¶”ë¡  í…ŒìŠ¤íŠ¸...")
test_queries = [
    "ê°•ì•„ì§€ê°€ ë…¸ë€ í† ë¥¼ í•´ìš”. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
    "ê³ ì–‘ì´ê°€ ë°¥ì„ ì•ˆ ë¨¹ì–´ìš”.",
    "ê°•ì•„ì§€ ì˜ˆë°©ì ‘ì¢…ì€ ì–¸ì œë¶€í„° í•´ì•¼ í•˜ë‚˜ìš”?"
]

print(f"\nì´ {len(test_queries)}ê°œ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n")

for i, query in enumerate(test_queries, 1):
    print("="*60)
    print(f"í…ŒìŠ¤íŠ¸ {i}/{len(test_queries)}")
    print("="*60)
    print(f"ì§ˆë¬¸: {query}\n")
    
    try:
        answer = pipeline.run(query)
        print(f"\nâœ… ì¶”ë¡  ì„±ê³µ!")
        print("="*60)
        
        # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „ ì§§ì€ ëŒ€ê¸°
        if i < len(test_queries):
            print("\në‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™...\n")
            import time
            time.sleep(2)
            
    except Exception as e:
        print(f"\nâŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        break

print("\n" + "="*60)
print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print("="*60)
print("\në‹¤ìŒ ë‹¨ê³„:")
print("1. ê²°ê³¼ê°€ ë§Œì¡±ìŠ¤ëŸ¬ìš°ë©´ ëª¨ë¸ì„ Hugging Faceì— ì—…ë¡œë“œí•˜ì„¸ìš”")
print("2. GitHubì— ì½”ë“œë¥¼ ì»¤ë°‹í•˜ê³  í‘¸ì‹œí•˜ì„¸ìš”")
print("3. README.mdë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”")
